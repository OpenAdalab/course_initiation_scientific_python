{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Afternoon Session Exercises\n",
    "## Lists, NumPy Arrays, and Pandas DataFrames\n",
    "\n",
    "**Instructions:**\n",
    "- Complete exercises appropriate to your skill level\n",
    "- Experiment and modify the code\n",
    "- Ask questions if you get stuck!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.4: Lists and Dictionaries (30 min)\n",
    "\n",
    "### Physics Context\n",
    "Detectors record \"hits\" when particles pass through sensor layers. Each hit has a position in space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beginner Version\n",
    "Work with detector hit positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances from origin:\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# List of hit positions as (x, y) tuples in meters\n",
    "hits = [\n",
    "    (0.5, 0.3),\n",
    "    (1.2, 0.8),\n",
    "    (0.2, 1.5),\n",
    "    (2.0, 0.5),\n",
    "    (0.8, 1.1)\n",
    "]\n",
    "\n",
    "# TODO: Calculate distance from origin for each hit\n",
    "# Distance formula: r = sqrt(xÂ² + yÂ²)\n",
    "\n",
    "distances = []  # Store results here\n",
    "\n",
    "# Method 1: Using a loop\n",
    "for hit in hits:\n",
    "    x, y = hit  # Unpack tuple\n",
    "    # YOUR CODE HERE : compute r \n",
    "    # YOUR CODE HERE : store r in distances\n",
    "\n",
    "\n",
    "print(\"Distances from origin:\")\n",
    "for i, d in enumerate(distances):\n",
    "    print(f\"Hit {i}: {d:.3f} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "distances = []\n",
    "\n",
    "for hit in hits:\n",
    "    x, y = hit\n",
    "    r = math.sqrt(x**2 + y**2)\n",
    "    distances.append(r)\n",
    "\n",
    "print(\"Distances from origin:\")\n",
    "for i, d in enumerate(distances):\n",
    "    print(f\"Hit {i}: {d:.3f} m\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Using list comprehension (more Pythonic)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"\\nDistances (list comprehension):\")\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "# Using list comprehension\n",
    "distances = [math.sqrt(x**2 + y**2) for x, y in hits]\n",
    "\n",
    "print(\"\\nDistances (list comprehension):\")\n",
    "print(distances)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the hit closest to the origin\n",
    "min_distance = # YOUR CODE HERE (use min())\n",
    "min_index = # YOUR CODE HERE (find index of minimum)\n",
    "closest_hit = hits[min_index]\n",
    "\n",
    "print(f\"\\nClosest hit: {closest_hit} at distance {min_distance:.3f} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "min_distance = min(distances)\n",
    "min_index = distances.index(min_distance)\n",
    "closest_hit = hits[min_index]\n",
    "\n",
    "print(f\"\\nClosest hit: {closest_hit} at distance {min_distance:.3f} m\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Version\n",
    "Work with detector geometry using nested dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# TODO: Create a nested dictionary for detector geometry\n",
    "detector = {\n",
    "    'barrel': {\n",
    "        'layers': [\n",
    "            {'name': 'Inner', 'radius': 0.5, 'z_max': 2.0},\n",
    "            {'name': 'Middle', 'radius': 1.0, 'z_max': 2.5},\n",
    "            {'name': 'Outer', 'radius': 1.5, 'z_max': 3.0}\n",
    "        ]\n",
    "    },\n",
    "    'endcap': {\n",
    "        'disks': [\n",
    "            {'name': 'EC1', 'z': 2.5, 'r_min': 0.3, 'r_max': 1.5},\n",
    "            {'name': 'EC2', 'z': 3.5, 'r_min': 0.3, 'r_max': 1.5}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print detector info\n",
    "print(\"Detector Configuration:\")\n",
    "print(f\"Number of barrel layers: {len(detector['barrel']['layers'])}\")\n",
    "print(f\"Number of endcap disks: {len(detector['endcap']['disks'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement coordinate transformations\n",
    "\n",
    "def cartesian_to_cylindrical(x, y, z):\n",
    "    \"\"\"\n",
    "    Convert Cartesian (x, y, z) to cylindrical (r, phi, z) coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x, y, z : float\n",
    "        Cartesian coordinates\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (r, phi, z) in cylindrical coordinates\n",
    "        r: radial distance from z-axis\n",
    "        phi: azimuthal angle in radians [-Ï€, Ï€]\n",
    "        z: same as input z\n",
    "    \"\"\"\n",
    "    r = # YOUR CODE HERE (sqrt(xÂ² + yÂ²))\n",
    "    phi = # YOUR CODE HERE (use math.atan2(y, x))\n",
    "    return r, phi, z\n",
    "\n",
    "def cylindrical_to_cartesian(r, phi, z):\n",
    "    \"\"\"\n",
    "    Convert cylindrical (r, phi, z) to Cartesian (x, y, z) coordinates.\n",
    "    \"\"\"\n",
    "    x = # YOUR CODE HERE\n",
    "    y = # YOUR CODE HERE\n",
    "    return x, y, z\n",
    "\n",
    "# Test transformations\n",
    "x, y, z = 1.0, 1.0, 2.0\n",
    "r, phi, z_cyl = cartesian_to_cylindrical(x, y, z)\n",
    "print(f\"Cartesian ({x}, {y}, {z}) â†’ Cylindrical ({r:.3f}, {phi:.3f}, {z_cyl})\")\n",
    "\n",
    "x2, y2, z2 = cylindrical_to_cartesian(r, phi, z_cyl)\n",
    "print(f\"Back to Cartesian: ({x2:.3f}, {y2:.3f}, {z2:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "def cartesian_to_cylindrical(x, y, z):\n",
    "    \"\"\"\n",
    "    Convert Cartesian (x, y, z) to cylindrical (r, phi, z) coordinates.\n",
    "    \"\"\"\n",
    "    r = math.sqrt(x**2 + y**2)\n",
    "    phi = math.atan2(y, x)\n",
    "    return r, phi, z\n",
    "\n",
    "def cylindrical_to_cartesian(r, phi, z):\n",
    "    \"\"\"\n",
    "    Convert cylindrical (r, phi, z) to Cartesian (x, y, z) coordinates.\n",
    "    \"\"\"\n",
    "    x = r * math.cos(phi)\n",
    "    y = r * math.sin(phi)\n",
    "    return x, y, z\n",
    "\n",
    "# Test transformations\n",
    "x, y, z = 1.0, 1.0, 2.0\n",
    "r, phi, z_cyl = cartesian_to_cylindrical(x, y, z)\n",
    "print(f\"Cartesian ({x}, {y}, {z}) â†’ Cylindrical ({r:.3f}, {phi:.3f}, {z_cyl})\")\n",
    "\n",
    "x2, y2, z2 = cylindrical_to_cartesian(r, phi, z_cyl)\n",
    "print(f\"Back to Cartesian: ({x2:.3f}, {y2:.3f}, {z2:.3f})\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Determine which detector layer each hit corresponds to\n",
    "\n",
    "# Simulated hits in Cartesian coordinates\n",
    "hits_3d = [\n",
    "    (0.4, 0.3, 1.0),   # Should be in Inner layer\n",
    "    (0.7, 0.7, 1.5),   # Should be in Middle layer\n",
    "    (1.2, 0.8, 2.0),   # Should be in Outer layer\n",
    "    (0.5, 0.3, 3.0),   # Should be in endcap\n",
    "]\n",
    "\n",
    "def identify_layer(x, y, z, detector_config):\n",
    "    \"\"\"\n",
    "    Identify which detector layer a hit belongs to.\n",
    "    \n",
    "    Returns: tuple (region, layer_name) or None if outside acceptance\n",
    "    \"\"\"\n",
    "    r, phi, z_pos = cartesian_to_cylindrical(x, y, z)\n",
    "    \n",
    "    # Check barrel layers\n",
    "    for layer in detector_config['barrel']['layers']:\n",
    "        # YOUR CODE HERE\n",
    "        # Check if r is close to layer radius and |z| < z_max\n",
    "        # Use tolerance for radius matching (e.g., Â±0.05 m)\n",
    "        pass\n",
    "    \n",
    "    # Check endcap disks\n",
    "    for disk in detector_config['endcap']['disks']:\n",
    "        # YOUR CODE HERE\n",
    "        # Check if |z| is close to disk z and r_min < r < r_max\n",
    "        pass\n",
    "    \n",
    "    return None  # Outside detector acceptance\n",
    "\n",
    "# Test the function\n",
    "for i, (x, y, z) in enumerate(hits_3d):\n",
    "    result = identify_layer(x, y, z, detector)\n",
    "    print(f\"Hit {i} at ({x}, {y}, {z}): {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "def identify_layer(x, y, z, detector_config):\n",
    "    \"\"\"\n",
    "    Identify which detector layer a hit belongs to.\n",
    "    \n",
    "    Returns: tuple (region, layer_name) or None if outside acceptance\n",
    "    \"\"\"\n",
    "    r, phi, z_pos = cartesian_to_cylindrical(x, y, z)\n",
    "    \n",
    "    # Check barrel layers\n",
    "    for layer in detector_config['barrel']['layers']:\n",
    "        radius_tolerance = 0.05\n",
    "        if abs(r - layer['radius']) < radius_tolerance and abs(z_pos) < layer['z_max']:\n",
    "            return ('barrel', layer['name'])\n",
    "    \n",
    "    # Check endcap disks\n",
    "    for disk in detector_config['endcap']['disks']:\n",
    "        z_tolerance = 0.1\n",
    "        if abs(abs(z_pos) - disk['z']) < z_tolerance:\n",
    "            if disk['r_min'] < r < disk['r_max']:\n",
    "                return ('endcap', disk['name'])\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Test the function\n",
    "for i, (x, y, z) in enumerate(hits_3d):\n",
    "    result = identify_layer(x, y, z, detector)\n",
    "    print(f\"Hit {i} at ({x}, {y}, {z}): {result}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 1.5: Advanced NumPy Operations (50 min)\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beginner Version\n",
    "Load and analyze simulated detector data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate simulated detector data (normally you'd load from file)\n",
    "np.random.seed(42)\n",
    "n_events = 10000\n",
    "\n",
    "# Simulate particle properties\n",
    "energies = np.random.exponential(scale=30, size=n_events)  # Exponential spectrum\n",
    "eta = np.random.uniform(-2.5, 2.5, n_events)  # Pseudorapidity\n",
    "phi = np.random.uniform(-np.pi, np.pi, n_events)  # Azimuthal angle\n",
    "\n",
    "# Add some detector noise\n",
    "energies += np.random.normal(0, 2, n_events)\n",
    "energies = np.maximum(energies, 0)  # Ensure positive energies\n",
    "\n",
    "print(f\"Generated {n_events} events\")\n",
    "print(f\"Energy range: {energies.min():.2f} - {energies.max():.2f} GeV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply energy threshold cuts using boolean masks\n",
    "\n",
    "# Define cut\n",
    "energy_threshold = 20.0  # GeV\n",
    "\n",
    "# Create boolean mask\n",
    "passes_cut = # YOUR CODE HERE\n",
    "\n",
    "# Apply cut\n",
    "energies_selected = energies[passes_cut]\n",
    "eta_selected = # YOUR CODE HERE\n",
    "phi_selected = # YOUR CODE HERE\n",
    "\n",
    "print(f\"\\nEvents passing E > {energy_threshold} GeV: {np.sum(passes_cut)}\")\n",
    "print(f\"Efficiency: {np.sum(passes_cut) / len(energies) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "# Define cut\n",
    "energy_threshold = 20.0  # GeV\n",
    "\n",
    "# Create boolean mask\n",
    "passes_cut = energies > energy_threshold\n",
    "\n",
    "# Apply cut\n",
    "energies_selected = energies[passes_cut]\n",
    "eta_selected = eta[passes_cut]\n",
    "phi_selected = phi[passes_cut]\n",
    "\n",
    "print(f\"\\nEvents passing E > {energy_threshold} GeV: {np.sum(passes_cut)}\")\n",
    "print(f\"Efficiency: {np.sum(passes_cut) / len(energies) * 100:.1f}%\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate statistics before and after cuts\n",
    "\n",
    "def print_statistics(data, label):\n",
    "    \"\"\"Print statistics for an array.\"\"\"\n",
    "    print(f\"\\n{label}:\")\n",
    "    print(f\"  Mean:   {np.mean(data):.2f}\")\n",
    "    print(f\"  Std:    {np.std(data):.2f}\")\n",
    "    print(f\"  Median: {np.median(data):.2f}\")\n",
    "    print(f\"  Min:    {np.min(data):.2f}\")\n",
    "    print(f\"  Max:    {np.max(data):.2f}\")\n",
    "\n",
    "print_statistics(energies, \"All Events\")\n",
    "print_statistics(energies_selected, f\"E > {energy_threshold} GeV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot distributions before and after cuts\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Energy distribution\n",
    "axes[0].hist(energies, bins=50, alpha=0.5, label='All events', range=(0, 150))\n",
    "axes[0].hist(energies_selected, bins=50, alpha=0.5, label=f'E > {energy_threshold} GeV', range=(0, 150))\n",
    "axes[0].axvline(energy_threshold, color='red', linestyle='--', label='Threshold')\n",
    "axes[0].set_xlabel('Energy (GeV)')\n",
    "axes[0].set_ylabel('Events')\n",
    "axes[0].legend()\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Eta distribution\n",
    "# YOUR CODE HERE (similar to above)\n",
    "\n",
    "# Phi distribution\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Energy distribution\n",
    "axes[0].hist(energies, bins=50, alpha=0.5, label='All events', range=(0, 150))\n",
    "axes[0].hist(energies_selected, bins=50, alpha=0.5, label=f'E > {energy_threshold} GeV', range=(0, 150))\n",
    "axes[0].axvline(energy_threshold, color='red', linestyle='--', label='Threshold')\n",
    "axes[0].set_xlabel('Energy (GeV)')\n",
    "axes[0].set_ylabel('Events')\n",
    "axes[0].legend()\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Eta distribution\n",
    "axes[1].hist(eta, bins=50, alpha=0.5, label='All events')\n",
    "axes[1].hist(eta_selected, bins=50, alpha=0.5, label=f'E > {energy_threshold} GeV')\n",
    "axes[1].set_xlabel('Î· (pseudorapidity)')\n",
    "axes[1].set_ylabel('Events')\n",
    "axes[1].legend()\n",
    "\n",
    "# Phi distribution\n",
    "axes[2].hist(phi, bins=50, alpha=0.5, label='All events')\n",
    "axes[2].hist(phi_selected, bins=50, alpha=0.5, label=f'E > {energy_threshold} GeV')\n",
    "axes[2].set_xlabel('Ï† (azimuthal angle)')\n",
    "axes[2].set_ylabel('Events')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Version\n",
    "Vectorized calculations and efficiency corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate invariant mass for all particle pairs in an event\n",
    "\n",
    "# Simulate an event with multiple particles\n",
    "# For simplicity, use (E, px, py, pz) representation\n",
    "np.random.seed(123)\n",
    "n_particles = 5\n",
    "\n",
    "# Generate 4-vectors\n",
    "E = np.random.uniform(20, 100, n_particles)\n",
    "px = np.random.uniform(-50, 50, n_particles)\n",
    "py = np.random.uniform(-50, 50, n_particles)\n",
    "pz = np.random.uniform(-50, 50, n_particles)\n",
    "\n",
    "# Ensure physical constraint: EÂ² â‰¥ pÂ²\n",
    "p2 = px**2 + py**2 + pz**2\n",
    "E = np.maximum(E, np.sqrt(p2) + 0.1)\n",
    "\n",
    "print(f\"Event with {n_particles} particles\")\n",
    "for i in range(n_particles):\n",
    "    print(f\"  Particle {i}: E={E[i]:.1f}, px={px[i]:.1f}, py={py[i]:.1f}, pz={pz[i]:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Using loops (slow, for comparison)\n",
    "import time\n",
    "\n",
    "def invariant_mass_loops(E, px, py, pz):\n",
    "    \"\"\"Calculate all pair masses using loops.\"\"\"\n",
    "    n = len(E)\n",
    "    masses = []\n",
    "    pairs = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):  # Avoid double-counting\n",
    "            E_sum = E[i] + E[j]\n",
    "            px_sum = px[i] + px[j]\n",
    "            py_sum = py[i] + py[j]\n",
    "            pz_sum = pz[i] + pz[j]\n",
    "            \n",
    "            p_sum2 = px_sum**2 + py_sum**2 + pz_sum**2\n",
    "            m2 = E_sum**2 - p_sum2\n",
    "            \n",
    "            if m2 >= 0:\n",
    "                masses.append(np.sqrt(m2))\n",
    "                pairs.append((i, j))\n",
    "    \n",
    "    return np.array(masses), pairs\n",
    "\n",
    "start = time.time()\n",
    "masses_loop, pairs = invariant_mass_loops(E, px, py, pz)\n",
    "time_loop = time.time() - start\n",
    "\n",
    "print(f\"\\nLoop method: {len(masses_loop)} pairs in {time_loop*1000:.3f} ms\")\n",
    "for (i, j), m in zip(pairs, masses_loop):\n",
    "    print(f\"  Pair ({i}, {j}): M = {m:.2f} GeV/cÂ²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Vectorized approach (fast!)\n",
    "\n",
    "def invariant_mass_vectorized(E, px, py, pz):\n",
    "    \"\"\"\n",
    "    Calculate all pair masses using vectorized operations.\n",
    "    \n",
    "    Uses broadcasting to compute all pairs at once.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Hint: Use broadcasting with E[:, None] + E[None, :]\n",
    "    # This creates a matrix of all pair sums\n",
    "    \n",
    "    E_sum = # YOUR CODE HERE\n",
    "    px_sum = # YOUR CODE HERE\n",
    "    py_sum = # YOUR CODE HERE\n",
    "    pz_sum = # YOUR CODE HERE\n",
    "    \n",
    "    # Calculate invariant mass squared\n",
    "    p_sum2 = px_sum**2 + py_sum**2 + pz_sum**2\n",
    "    m2 = E_sum**2 - p_sum2\n",
    "    \n",
    "    # Extract upper triangle (avoid double-counting and self-pairs)\n",
    "    n = len(E)\n",
    "    i_indices, j_indices = np.triu_indices(n, k=1)\n",
    "    \n",
    "    masses = np.sqrt(np.maximum(m2[i_indices, j_indices], 0))\n",
    "    \n",
    "    return masses\n",
    "\n",
    "start = time.time()\n",
    "masses_vec = invariant_mass_vectorized(E, px, py, pz)\n",
    "time_vec = time.time() - start\n",
    "\n",
    "print(f\"\\nVectorized method: {len(masses_vec)} pairs in {time_vec*1000:.3f} ms\")\n",
    "print(f\"Speedup: {time_loop/time_vec:.1f}x\")\n",
    "print(f\"Results match: {np.allclose(masses_loop, masses_vec)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "def invariant_mass_vectorized(E, px, py, pz):\n",
    "    \"\"\"\n",
    "    Calculate all pair masses using vectorized operations.\n",
    "    \n",
    "    Uses broadcasting to compute all pairs at once.\n",
    "    \"\"\"\n",
    "    # Broadcasting: [:, None] creates column, [None, :] creates row\n",
    "    E_sum = E[:, None] + E[None, :]\n",
    "    px_sum = px[:, None] + px[None, :]\n",
    "    py_sum = py[:, None] + py[None, :]\n",
    "    pz_sum = pz[:, None] + pz[None, :]\n",
    "    \n",
    "    # Calculate invariant mass squared\n",
    "    p_sum2 = px_sum**2 + py_sum**2 + pz_sum**2\n",
    "    m2 = E_sum**2 - p_sum2\n",
    "    \n",
    "    # Extract upper triangle (avoid double-counting and self-pairs)\n",
    "    n = len(E)\n",
    "    i_indices, j_indices = np.triu_indices(n, k=1)\n",
    "    \n",
    "    masses = np.sqrt(np.maximum(m2[i_indices, j_indices], 0))\n",
    "    \n",
    "    return masses\n",
    "\n",
    "start = time.time()\n",
    "masses_vec = invariant_mass_vectorized(E, px, py, pz)\n",
    "time_vec = time.time() - start\n",
    "\n",
    "print(f\"\\nVectorized method: {len(masses_vec)} pairs in {time_vec*1000:.3f} ms\")\n",
    "print(f\"Speedup: {time_loop/time_vec:.1f}x\")\n",
    "print(f\"Results match: {np.allclose(masses_loop, masses_vec)}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement detector efficiency corrections\n",
    "\n",
    "# Create 2D efficiency map (eta vs phi)\n",
    "eta_bins = np.linspace(-2.5, 2.5, 50)\n",
    "phi_bins = np.linspace(-np.pi, np.pi, 50)\n",
    "\n",
    "# Simulate realistic efficiency (lower at edges)\n",
    "eta_centers = (eta_bins[:-1] + eta_bins[1:]) / 2\n",
    "phi_centers = (phi_bins[:-1] + phi_bins[1:]) / 2\n",
    "\n",
    "# Create 2D efficiency map\n",
    "eta_2d, phi_2d = np.meshgrid(eta_centers, phi_centers, indexing='ij')\n",
    "efficiency_map = 0.95 * np.exp(-0.1 * eta_2d**2)  # Gaussian in eta\n",
    "\n",
    "# Visualize efficiency map\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(efficiency_map, extent=[-np.pi, np.pi, -2.5, 2.5], \n",
    "           origin='lower', aspect='auto', cmap='viridis')\n",
    "plt.colorbar(label='Efficiency')\n",
    "plt.xlabel('Ï† (rad)')\n",
    "plt.ylabel('Î·')\n",
    "plt.title('Detector Efficiency Map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply efficiency corrections to event weights\n",
    "\n",
    "def get_efficiency(eta, phi, efficiency_map, eta_bins, phi_bins):\n",
    "    \"\"\"\n",
    "    Look up efficiency for given eta, phi values.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Use np.digitize to find which bin each value falls into\n",
    "    # Then look up efficiency from the map\n",
    "    pass\n",
    "\n",
    "# Apply to our data\n",
    "event_efficiency = get_efficiency(eta_selected, phi_selected, \n",
    "                                   efficiency_map, eta_bins, phi_bins)\n",
    "\n",
    "# Weight each event by 1/efficiency to correct for losses\n",
    "weights = 1.0 / event_efficiency\n",
    "\n",
    "print(f\"\\nEfficiency statistics:\")\n",
    "print(f\"  Mean efficiency: {np.mean(event_efficiency):.3f}\")\n",
    "print(f\"  Min efficiency:  {np.min(event_efficiency):.3f}\")\n",
    "print(f\"  Max weight:      {np.max(weights):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "def get_efficiency(eta, phi, efficiency_map, eta_bins, phi_bins):\n",
    "    \"\"\"\n",
    "    Look up efficiency for given eta, phi values.\n",
    "    \"\"\"\n",
    "    # Find bin indices for each value\n",
    "    eta_idx = np.digitize(eta, eta_bins) - 1\n",
    "    phi_idx = np.digitize(phi, phi_bins) - 1\n",
    "    \n",
    "    # Clip to valid range\n",
    "    eta_idx = np.clip(eta_idx, 0, len(eta_bins) - 2)\n",
    "    phi_idx = np.clip(phi_idx, 0, len(phi_bins) - 2)\n",
    "    \n",
    "    # Look up efficiency\n",
    "    return efficiency_map[eta_idx, phi_idx]\n",
    "\n",
    "# Apply to our data\n",
    "event_efficiency = get_efficiency(eta_selected, phi_selected, \n",
    "                                   efficiency_map, eta_bins, phi_bins)\n",
    "\n",
    "# Weight each event by 1/efficiency to correct for losses\n",
    "weights = 1.0 / event_efficiency\n",
    "\n",
    "print(f\"\\nEfficiency statistics:\")\n",
    "print(f\"  Mean efficiency: {np.mean(event_efficiency):.3f}\")\n",
    "print(f\"  Min efficiency:  {np.min(event_efficiency):.3f}\")\n",
    "print(f\"  Max weight:      {np.max(weights):.3f}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise 1.6: Pandas DataFrames (35 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beginner Version\n",
    "Load and filter collision data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate simulated collision data\n",
    "np.random.seed(42)\n",
    "n_events = 1000\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'event': range(n_events),\n",
    "    'run': np.random.choice([1, 2, 3], n_events),\n",
    "    'trigger': np.random.choice([True, False], n_events, p=[0.3, 0.7]),\n",
    "    'energy': np.random.exponential(40, n_events),\n",
    "    'px': np.random.normal(0, 20, n_events),\n",
    "    'py': np.random.normal(0, 20, n_events),\n",
    "    'eta': np.random.uniform(-2.5, 2.5, n_events),\n",
    "    'phi': np.random.uniform(-np.pi, np.pi, n_events)\n",
    "})\n",
    "\n",
    "print(f\"Generated {len(data)} events\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Filter events by trigger condition\n",
    "\n",
    "triggered_data = # YOUR CODE HERE\n",
    "\n",
    "print(f\"\\nEvents passing trigger: {len(triggered_data)}\")\n",
    "print(f\"Trigger efficiency: {len(triggered_data) / len(data) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "triggered_data = data[data['trigger'] == True]\n",
    "\n",
    "print(f\"\\nEvents passing trigger: {len(triggered_data)}\")\n",
    "print(f\"Trigger efficiency: {len(triggered_data) / len(data) * 100:.1f}%\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate and add transverse momentum column\n",
    "# pt = sqrt(pxÂ² + pyÂ²)\n",
    "\n",
    "data['pt'] = # YOUR CODE HERE\n",
    "\n",
    "# Also calculate transverse energy\n",
    "# Et = E / cosh(eta)\n",
    "data['Et'] = # YOUR CODE HERE\n",
    "\n",
    "print(\"\\nNew columns added:\")\n",
    "data[['energy', 'px', 'py', 'pt', 'eta', 'Et']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "# Calculate transverse momentum\n",
    "data['pt'] = np.sqrt(data['px']**2 + data['py']**2)\n",
    "\n",
    "# Calculate transverse energy\n",
    "data['Et'] = data['energy'] / np.cosh(data['eta'])\n",
    "\n",
    "print(\"\\nNew columns added:\")\n",
    "data[['energy', 'px', 'py', 'pt', 'eta', 'Et']].head()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create summary statistics\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(data[['energy', 'pt', 'Et']].describe())\n",
    "\n",
    "# Statistics by run\n",
    "print(\"\\nStatistics by run:\")\n",
    "# YOUR CODE HERE (use groupby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(data[['energy', 'pt', 'Et']].describe())\n",
    "\n",
    "# Statistics by run\n",
    "print(\"\\nStatistics by run:\")\n",
    "print(data.groupby('run')[['energy', 'pt', 'Et']].mean())\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Version\n",
    "Complex multi-DataFrame analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create event-level and particle-level DataFrames\n",
    "\n",
    "# Event-level info\n",
    "events = pd.DataFrame({\n",
    "    'event': range(100),\n",
    "    'run': np.random.choice([1, 2, 3], 100),\n",
    "    'luminosity': np.random.uniform(1e33, 2e33, 100),\n",
    "    'trigger_HLT': np.random.choice([True, False], 100, p=[0.3, 0.7])\n",
    "})\n",
    "\n",
    "# Particle-level info (multiple particles per event)\n",
    "particle_list = []\n",
    "for event_id in range(100):\n",
    "    n_particles = np.random.poisson(3)  # Average 3 particles per event\n",
    "    for _ in range(n_particles):\n",
    "        particle_list.append({\n",
    "            'event': event_id,\n",
    "            'particle_type': np.random.choice(['e', 'mu', 'photon']),\n",
    "            'energy': np.random.exponential(30),\n",
    "            'pt': np.random.exponential(20),\n",
    "            'eta': np.random.uniform(-2.5, 2.5),\n",
    "            'phi': np.random.uniform(-np.pi, np.pi)\n",
    "        })\n",
    "\n",
    "particles = pd.DataFrame(particle_list)\n",
    "\n",
    "print(f\"Events: {len(events)}\")\n",
    "print(f\"Particles: {len(particles)}\")\n",
    "print(f\"Average particles per event: {len(particles) / len(events):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Merge DataFrames\n",
    "\n",
    "# Merge particle data with event info\n",
    "merged = # YOUR CODE HERE (use pd.merge)\n",
    "\n",
    "# Apply event-level cuts\n",
    "merged_triggered = # YOUR CODE HERE (filter by trigger_HLT)\n",
    "\n",
    "print(f\"\\nParticles after merging and trigger: {len(merged_triggered)}\")\n",
    "merged_triggered.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "# Merge particle data with event info\n",
    "merged = pd.merge(particles, events, on='event', how='left')\n",
    "\n",
    "# Apply event-level cuts\n",
    "merged_triggered = merged[merged['trigger_HLT'] == True]\n",
    "\n",
    "print(f\"\\nParticles after merging and trigger: {len(merged_triggered)}\")\n",
    "merged_triggered.head(10)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate event-level quantities using groupby\n",
    "\n",
    "event_summary = merged_triggered.groupby('event').agg({\n",
    "    'energy': ['sum', 'mean', 'max'],  # Total, average, max energy\n",
    "    'pt': 'sum',                        # Total pt\n",
    "    'particle_type': 'count'            # Number of particles\n",
    "})\n",
    "\n",
    "event_summary.columns = ['_'.join(col).strip() for col in event_summary.columns]\n",
    "event_summary = event_summary.rename(columns={'particle_type_count': 'n_particles'})\n",
    "\n",
    "print(\"\\nEvent-level summary:\")\n",
    "print(event_summary.head())\n",
    "print(f\"\\nAverage particles per triggered event: {event_summary['n_particles'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find leading (highest pT) particle per event\n",
    "\n",
    "# Method 1: Using groupby and idxmax\n",
    "leading_particles = merged_triggered.loc[\n",
    "    merged_triggered.groupby('event')['pt'].idxmax()\n",
    "]\n",
    "\n",
    "print(\"\\nLeading particles:\")\n",
    "print(leading_particles[['event', 'particle_type', 'pt', 'eta']].head())\n",
    "\n",
    "# Plot leading particle pT distribution by type\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for ptype in ['e', 'mu', 'photon']:\n",
    "    subset = leading_particles[leading_particles['particle_type'] == ptype]\n",
    "    ax.hist(subset['pt'], bins=20, alpha=0.5, label=ptype, range=(0, 100))\n",
    "\n",
    "ax.set_xlabel('Leading particle pT (GeV/c)')\n",
    "ax.set_ylabel('Events')\n",
    "ax.set_title('Leading Particle pT Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Handle missing data\n",
    "\n",
    "# Introduce some missing values\n",
    "test_data = particles.copy()\n",
    "mask = np.random.random(len(test_data)) < 0.1\n",
    "test_data.loc[mask, 'energy'] = np.nan\n",
    "\n",
    "print(f\"\\nMissing values:\")\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Options:\n",
    "# 1. Drop rows with missing energy\n",
    "# 2. Fill with median energy\n",
    "# 3. Fill with mean by particle type\n",
    "\n",
    "# Method 3 example:\n",
    "test_data['energy'] = test_data.groupby('particle_type')['energy'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "print(f\"\\nAfter filling:\")\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus: Integration Exercise\n",
    "\n",
    "Combine everything into a complete analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a complete analysis pipeline that:\n",
    "# 1. Loads data\n",
    "# 2. Applies quality cuts\n",
    "# 3. Calculates derived quantities\n",
    "# 4. Makes summary plots\n",
    "# 5. Exports results\n",
    "\n",
    "def analyze_collision_data(data_df, energy_cut=20, eta_cut=2.5):\n",
    "    \"\"\"\n",
    "    Complete analysis pipeline for collision data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_df : pd.DataFrame\n",
    "        Input data\n",
    "    energy_cut : float\n",
    "        Minimum energy in GeV\n",
    "    eta_cut : float\n",
    "        Maximum |eta|\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Analyzed data with cuts applied\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Test the pipeline\n",
    "# results = analyze_collision_data(data)\n",
    "# results.to_csv('analysis_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ðŸ’¡ Click to reveal solution</summary>\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate simulated collision events\n",
    "np.random.seed(42)\n",
    "n_events = 1000\n",
    "\n",
    "# Create event data\n",
    "events = pd.DataFrame({\n",
    "    'event': range(n_events),\n",
    "    'n_particles': np.random.poisson(5, n_events),\n",
    "    'trigger': np.random.choice([True, False], n_events, p=[0.7, 0.3])\n",
    "})\n",
    "\n",
    "# Apply trigger cut\n",
    "triggered_events = events[events['trigger']]\n",
    "\n",
    "# Generate particle-level data for triggered events\n",
    "particle_data = []\n",
    "for idx, row in triggered_events.iterrows():\n",
    "    for i in range(row['n_particles']):\n",
    "        particle_data.append({\n",
    "            'event': row['event'],\n",
    "            'energy': np.random.exponential(30),\n",
    "            'eta': np.random.uniform(-2.5, 2.5),\n",
    "            'phi': np.random.uniform(-np.pi, np.pi)\n",
    "        })\n",
    "\n",
    "particles = pd.DataFrame(particle_data)\n",
    "\n",
    "# Calculate transverse energy\n",
    "particles['Et'] = particles['energy'] / np.cosh(particles['eta'])\n",
    "\n",
    "# Event selection: at least one high-Et particle\n",
    "good_events = particles[particles['Et'] > 50]['event'].unique()\n",
    "final_data = particles[particles['event'].isin(good_events)]\n",
    "\n",
    "print(f\"Started with {n_events} events\")\n",
    "print(f\"After trigger: {len(triggered_events)} events\")\n",
    "print(f\"After Et cut: {len(good_events)} events\")\n",
    "print(f\"Final particles: {len(final_data)}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(particles['energy'], bins=50)\n",
    "plt.xlabel('Energy (GeV)')\n",
    "plt.ylabel('Particles')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(particles['Et'], bins=50)\n",
    "plt.xlabel('Et (GeV)')\n",
    "plt.ylabel('Particles')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist2d(particles['eta'], particles['phi'], bins=30)\n",
    "plt.xlabel('Î·')\n",
    "plt.ylabel('Ï†')\n",
    "plt.colorbar(label='Particles')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Today you learned:\n",
    "\n",
    "âœ… Python **lists** and **dictionaries** for flexible data structures  \n",
    "âœ… Advanced **NumPy** techniques: boolean masking, broadcasting, vectorization  \n",
    "âœ… **Pandas DataFrames** for tabular data analysis  \n",
    "âœ… Realistic particle physics workflows: loading, filtering, grouping, merging  \n",
    "âœ… Performance optimization: vectorized operations are 10-100x faster!  \n",
    "\n",
    "**Tomorrow:** Functions, classes, and structuring analysis code professionally!\n",
    "\n",
    "---\n",
    "\n",
    "**Great work today! ðŸŽ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cours",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
